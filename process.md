
系统设计
如下图所示，无人机采集视频作为服务器端，每个视频都被以不同的比特率编码存储而且每个视频都被分割为多个视频块。无人机将所处信息发送给客户端，客户端根据无人机所处的状态信息对下一个视频快的比特率进行选择，然后通过无线网络发送给服务器端请求发送视频块，服务器将该视频块以请求的比特率进行传输，从而完成此视频块的传输过程。 
![](https://i.imgur.com/XVfYrC5.png)

我们所做的工作就是进行视频块比特率的选择。所采取的深度强化学习架构如下： 
![](https://res.cloudinary.com/dpvywdzxv/image/upload/v1552644740/samples/java%20files/%E6%8D%95%E8%8E%B79.jpg)
由图可知，网络的输入主要分为三部分信息：过去时刻的吞吐量[x1,x2,...,x8]、客户端视频信息（主要包括上一视频块的比特率lt、视频缓存大小dt）、传感器信息（主要包括速度pt、加速度at、距离dt）。吞吐量信息通过LSTM网络之后再和视频信息以及传感器信息通过DNN组成actor-critic网络。 具体的实现在实验部分会谈到。

实验数据采集
实验中主要是通过无人机上绑定手机作为发送端（服务器端），电脑作为接收端来采集数据的。无人机上安装我们自己编写的简易安卓程序（如图所示）来发送udp数据，数据包包括传感器等信息，电脑接收端安装wireshark接收udp数据包，通过每秒内收到的数据包的个数来计算此刻的吞吐量。 
